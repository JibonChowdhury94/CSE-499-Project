{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (40, 40, 3)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Dense(units = 50, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fitting the CNN model to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = .2, rotation_range = 25)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Dataset/Train', target_size = (40, 40),\n",
    "                                                 batch_size = 32, class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('Dataset/Test', target_size = (40, 40),\n",
    "                                            batch_size = 32, class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "358/358 [==============================] - ETA: 0s - loss: 3.4573 - accuracy: 0.1208WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "358/358 [==============================] - 481s 1s/step - loss: 3.4554 - accuracy: 0.1212 - val_loss: 1.1631 - val_accuracy: 0.6837\n",
      "Epoch 2/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 1.5602 - accuracy: 0.5506\n",
      "Epoch 3/100\n",
      "358/358 [==============================] - 59s 163ms/step - loss: 1.1564 - accuracy: 0.6612\n",
      "Epoch 4/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.9956 - accuracy: 0.7092\n",
      "Epoch 5/100\n",
      "358/358 [==============================] - 65s 182ms/step - loss: 0.8698 - accuracy: 0.7392\n",
      "Epoch 6/100\n",
      "358/358 [==============================] - 71s 198ms/step - loss: 0.8076 - accuracy: 0.7468\n",
      "Epoch 7/100\n",
      "358/358 [==============================] - 60s 166ms/step - loss: 0.7283 - accuracy: 0.7781\n",
      "Epoch 8/100\n",
      "358/358 [==============================] - 65s 181ms/step - loss: 0.6888 - accuracy: 0.7913\n",
      "Epoch 9/100\n",
      "358/358 [==============================] - 66s 184ms/step - loss: 0.6589 - accuracy: 0.8012\n",
      "Epoch 10/100\n",
      "358/358 [==============================] - 72s 202ms/step - loss: 0.6236 - accuracy: 0.8121\n",
      "Epoch 11/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.5851 - accuracy: 0.8186\n",
      "Epoch 12/100\n",
      "358/358 [==============================] - 71s 197ms/step - loss: 0.5600 - accuracy: 0.8252\n",
      "Epoch 13/100\n",
      "358/358 [==============================] - 73s 204ms/step - loss: 0.5395 - accuracy: 0.8267\n",
      "Epoch 14/100\n",
      "358/358 [==============================] - 69s 192ms/step - loss: 0.5256 - accuracy: 0.8339\n",
      "Epoch 15/100\n",
      "358/358 [==============================] - 69s 193ms/step - loss: 0.5215 - accuracy: 0.8334\n",
      "Epoch 16/100\n",
      "358/358 [==============================] - 75s 210ms/step - loss: 0.4833 - accuracy: 0.8448\n",
      "Epoch 17/100\n",
      "358/358 [==============================] - 70s 195ms/step - loss: 0.4778 - accuracy: 0.8437\n",
      "Epoch 18/100\n",
      "358/358 [==============================] - 71s 198ms/step - loss: 0.4812 - accuracy: 0.8512\n",
      "Epoch 19/100\n",
      "358/358 [==============================] - 73s 203ms/step - loss: 0.4574 - accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "358/358 [==============================] - 70s 195ms/step - loss: 0.4576 - accuracy: 0.8491\n",
      "Epoch 21/100\n",
      "358/358 [==============================] - 70s 197ms/step - loss: 0.4300 - accuracy: 0.8640\n",
      "Epoch 22/100\n",
      "358/358 [==============================] - 70s 196ms/step - loss: 0.4070 - accuracy: 0.8689\n",
      "Epoch 23/100\n",
      "358/358 [==============================] - 71s 199ms/step - loss: 0.3916 - accuracy: 0.8756\n",
      "Epoch 24/100\n",
      "358/358 [==============================] - 71s 199ms/step - loss: 0.3953 - accuracy: 0.8683\n",
      "Epoch 25/100\n",
      "358/358 [==============================] - 70s 195ms/step - loss: 0.3895 - accuracy: 0.8751\n",
      "Epoch 26/100\n",
      "358/358 [==============================] - 70s 195ms/step - loss: 0.3861 - accuracy: 0.8815\n",
      "Epoch 27/100\n",
      "358/358 [==============================] - 72s 201ms/step - loss: 0.3787 - accuracy: 0.8744\n",
      "Epoch 28/100\n",
      "358/358 [==============================] - 66s 183ms/step - loss: 0.3680 - accuracy: 0.8767\n",
      "Epoch 29/100\n",
      "358/358 [==============================] - 68s 189ms/step - loss: 0.3458 - accuracy: 0.8891\n",
      "Epoch 30/100\n",
      "358/358 [==============================] - 70s 194ms/step - loss: 0.3515 - accuracy: 0.8873\n",
      "Epoch 31/100\n",
      "358/358 [==============================] - 65s 181ms/step - loss: 0.3485 - accuracy: 0.8854\n",
      "Epoch 32/100\n",
      "358/358 [==============================] - 70s 195ms/step - loss: 0.3513 - accuracy: 0.8847s - los\n",
      "Epoch 33/100\n",
      "358/358 [==============================] - 65s 181ms/step - loss: 0.3322 - accuracy: 0.8960\n",
      "Epoch 34/100\n",
      "358/358 [==============================] - 65s 182ms/step - loss: 0.3380 - accuracy: 0.8914\n",
      "Epoch 35/100\n",
      "358/358 [==============================] - 64s 177ms/step - loss: 0.3113 - accuracy: 0.8964\n",
      "Epoch 36/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.3142 - accuracy: 0.8975\n",
      "Epoch 37/100\n",
      "358/358 [==============================] - 63s 177ms/step - loss: 0.3182 - accuracy: 0.8933\n",
      "Epoch 38/100\n",
      "358/358 [==============================] - 65s 181ms/step - loss: 0.3155 - accuracy: 0.8961\n",
      "Epoch 39/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.3122 - accuracy: 0.9001\n",
      "Epoch 40/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.3078 - accuracy: 0.9012\n",
      "Epoch 41/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.2998 - accuracy: 0.9048\n",
      "Epoch 42/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.3067 - accuracy: 0.8974\n",
      "Epoch 43/100\n",
      "358/358 [==============================] - 64s 179ms/step - loss: 0.2928 - accuracy: 0.9047\n",
      "Epoch 44/100\n",
      "358/358 [==============================] - 65s 182ms/step - loss: 0.2961 - accuracy: 0.9034\n",
      "Epoch 45/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.2919 - accuracy: 0.9005s - loss: 0.2919 - accuracy: \n",
      "Epoch 46/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.2756 - accuracy: 0.9073\n",
      "Epoch 47/100\n",
      "358/358 [==============================] - 64s 179ms/step - loss: 0.2966 - accuracy: 0.9052\n",
      "Epoch 48/100\n",
      "358/358 [==============================] - 65s 181ms/step - loss: 0.2716 - accuracy: 0.9122\n",
      "Epoch 49/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.2872 - accuracy: 0.9067\n",
      "Epoch 50/100\n",
      "358/358 [==============================] - 64s 178ms/step - loss: 0.2675 - accuracy: 0.9100\n",
      "Epoch 51/100\n",
      "358/358 [==============================] - 62s 174ms/step - loss: 0.2875 - accuracy: 0.9090\n",
      "Epoch 52/100\n",
      "358/358 [==============================] - 62s 174ms/step - loss: 0.2721 - accuracy: 0.9106\n",
      "Epoch 53/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.2511 - accuracy: 0.9180\n",
      "Epoch 54/100\n",
      "358/358 [==============================] - 62s 174ms/step - loss: 0.2422 - accuracy: 0.9188\n",
      "Epoch 55/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.2733 - accuracy: 0.9091\n",
      "Epoch 56/100\n",
      "358/358 [==============================] - 62s 174ms/step - loss: 0.2462 - accuracy: 0.9175\n",
      "Epoch 57/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.2551 - accuracy: 0.9183\n",
      "Epoch 58/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.2385 - accuracy: 0.9234s - loss: 0.2383 - accuracy\n",
      "Epoch 59/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.2557 - accuracy: 0.9139s -\n",
      "Epoch 60/100\n",
      "358/358 [==============================] - 63s 176ms/step - loss: 0.2467 - accuracy: 0.9190\n",
      "Epoch 61/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.2266 - accuracy: 0.9239\n",
      "Epoch 62/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.2467 - accuracy: 0.9179\n",
      "Epoch 63/100\n",
      "358/358 [==============================] - 72s 201ms/step - loss: 0.2515 - accuracy: 0.9229\n",
      "Epoch 64/100\n",
      "358/358 [==============================] - 89s 247ms/step - loss: 0.2320 - accuracy: 0.9243\n",
      "Epoch 65/100\n",
      "358/358 [==============================] - 89s 247ms/step - loss: 0.2174 - accuracy: 0.9288\n",
      "Epoch 66/100\n",
      "358/358 [==============================] - 89s 249ms/step - loss: 0.2456 - accuracy: 0.9200\n",
      "Epoch 67/100\n",
      "358/358 [==============================] - 88s 245ms/step - loss: 0.2336 - accuracy: 0.9190\n",
      "Epoch 68/100\n",
      "358/358 [==============================] - 88s 246ms/step - loss: 0.2212 - accuracy: 0.9258\n",
      "Epoch 69/100\n",
      "358/358 [==============================] - 88s 246ms/step - loss: 0.2448 - accuracy: 0.9183\n",
      "Epoch 70/100\n",
      "358/358 [==============================] - 88s 246ms/step - loss: 0.2306 - accuracy: 0.9214\n",
      "Epoch 71/100\n",
      "358/358 [==============================] - 89s 247ms/step - loss: 0.2454 - accuracy: 0.9181\n",
      "Epoch 72/100\n",
      "358/358 [==============================] - 90s 251ms/step - loss: 0.2295 - accuracy: 0.9235\n",
      "Epoch 73/100\n",
      "358/358 [==============================] - 89s 249ms/step - loss: 0.2172 - accuracy: 0.9261\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 89s 248ms/step - loss: 0.2188 - accuracy: 0.9291\n",
      "Epoch 75/100\n",
      "358/358 [==============================] - 89s 250ms/step - loss: 0.2245 - accuracy: 0.9282\n",
      "Epoch 76/100\n",
      "358/358 [==============================] - 793s 2s/step - loss: 0.2274 - accuracy: 0.9260\n",
      "Epoch 77/100\n",
      "358/358 [==============================] - 169s 473ms/step - loss: 0.2258 - accuracy: 0.9281\n",
      "Epoch 78/100\n",
      "358/358 [==============================] - 53s 147ms/step - loss: 0.2153 - accuracy: 0.9306\n",
      "Epoch 79/100\n",
      "358/358 [==============================] - 61s 172ms/step - loss: 0.2154 - accuracy: 0.9288\n",
      "Epoch 80/100\n",
      "358/358 [==============================] - 63s 175ms/step - loss: 0.2075 - accuracy: 0.9332\n",
      "Epoch 81/100\n",
      "358/358 [==============================] - 61s 170ms/step - loss: 0.2171 - accuracy: 0.9282\n",
      "Epoch 82/100\n",
      "358/358 [==============================] - 60s 167ms/step - loss: 0.2238 - accuracy: 0.9240\n",
      "Epoch 83/100\n",
      "358/358 [==============================] - 58s 162ms/step - loss: 0.2169 - accuracy: 0.9267\n",
      "Epoch 84/100\n",
      "358/358 [==============================] - 58s 163ms/step - loss: 0.2187 - accuracy: 0.9255\n",
      "Epoch 85/100\n",
      "358/358 [==============================] - 58s 163ms/step - loss: 0.2024 - accuracy: 0.9338\n",
      "Epoch 86/100\n",
      "358/358 [==============================] - 59s 166ms/step - loss: 0.2119 - accuracy: 0.9304\n",
      "Epoch 87/100\n",
      "358/358 [==============================] - 60s 166ms/step - loss: 0.2103 - accuracy: 0.9312\n",
      "Epoch 88/100\n",
      "358/358 [==============================] - 59s 163ms/step - loss: 0.2057 - accuracy: 0.9300\n",
      "Epoch 89/100\n",
      "358/358 [==============================] - 59s 166ms/step - loss: 0.2050 - accuracy: 0.9343\n",
      "Epoch 90/100\n",
      "358/358 [==============================] - 59s 164ms/step - loss: 0.2032 - accuracy: 0.9365\n",
      "Epoch 91/100\n",
      "358/358 [==============================] - 59s 166ms/step - loss: 0.2071 - accuracy: 0.9314\n",
      "Epoch 92/100\n",
      "358/358 [==============================] - 59s 165ms/step - loss: 0.1952 - accuracy: 0.9345\n",
      "Epoch 93/100\n",
      "358/358 [==============================] - 59s 165ms/step - loss: 0.1933 - accuracy: 0.9359\n",
      "Epoch 94/100\n",
      "358/358 [==============================] - 60s 167ms/step - loss: 0.2033 - accuracy: 0.9372\n",
      "Epoch 95/100\n",
      "358/358 [==============================] - 60s 167ms/step - loss: 0.2007 - accuracy: 0.9324\n",
      "Epoch 96/100\n",
      "358/358 [==============================] - 60s 166ms/step - loss: 0.2055 - accuracy: 0.9336\n",
      "Epoch 97/100\n",
      "358/358 [==============================] - 60s 166ms/step - loss: 0.1937 - accuracy: 0.9359\n",
      "Epoch 98/100\n",
      "358/358 [==============================] - 60s 166ms/step - loss: 0.2058 - accuracy: 0.9309\n",
      "Epoch 99/100\n",
      "358/358 [==============================] - 60s 166ms/step - loss: 0.1987 - accuracy: 0.9338\n",
      "Epoch 100/100\n",
      "358/358 [==============================] - 60s 166ms/step - loss: 0.2099 - accuracy: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17dc57ee820>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_set, steps_per_epoch = 358, epochs = 100,\n",
    "                         validation_data = test_set, validation_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 38, 38, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 17, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "=================================================================\n",
      "Total params: 608,242\n",
      "Trainable params: 608,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "classifier_json = classifier.to_json()\n",
    "with open(\"ModelSaving.json\", \"w\") as json_file:\n",
    "        json_file.write(classifier_json)\n",
    "          \n",
    "classifier.save_weights(\"ModelSaving.h5\")\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graphical user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import ImageTk, ImageDraw, Image\n",
    "from tkinter import *\n",
    "from keras.preprocessing import image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_image():\n",
    "    width = 256\n",
    "    height = 256\n",
    "    center = height // 2\n",
    "    white = (255, 255, 255)\n",
    "    green = (0, 128, 0)\n",
    "    \n",
    "    def save():\n",
    "        filename = 'F:\\Bengali-Handwritten-Character-Recognition-main\\Dataset\\Predict\\image.jpg'\n",
    "        image.save(filename)\n",
    "        \n",
    "    def paint(event):\n",
    "        x1, y1 = (event.x - 1), (event.y - 1)\n",
    "        x2, y2 = (event.x + 1), (event.y + 1)\n",
    "        cv.create_oval(x1, y1, x2, y2, fill = 'black', width = 30)\n",
    "        draw.line([x1, y1, x2, y2], fill = 'black', width = 30)\n",
    "        \n",
    "    root = Tk()\n",
    "    \n",
    "    cv = Canvas(root, width = width, height = height, bg = 'white')\n",
    "    cv.pack()\n",
    "    \n",
    "    image = PIL.Image.new('RGB', (width, height), white)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    cv.pack(expand = YES, fill = BOTH)\n",
    "    cv.bind(\"<B1-Motion>\", paint)\n",
    "    \n",
    "    button = Button(text = 'Save', command = save)\n",
    "    button.pack()\n",
    "    \n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_character(res):\n",
    "    if res == 0:\n",
    "        print('prediction : অ')\n",
    "    elif res == 1:\n",
    "        print('prediction : আ')\n",
    "    elif res == 2:\n",
    "        print('prediction : ই')\n",
    "    elif res == 3:\n",
    "        print('prediction : ঈ')\n",
    "    elif res == 4:\n",
    "        print('prediction : উ')\n",
    "    elif res == 5:\n",
    "        print('prediction : ঊ')\n",
    "    elif res == 6:\n",
    "        print('prediction : ঋ')\n",
    "    elif res == 7:\n",
    "        print('prediction : এ')\n",
    "    elif res == 8:\n",
    "        print('prediction : ঐ')\n",
    "    elif res == 9:\n",
    "        print('prediction : ও')\n",
    "    elif res == 10:\n",
    "        print('prediction : ঔ')\n",
    "    elif res == 11:\n",
    "        print('prediction : ক')\n",
    "    elif res == 12:\n",
    "        print('prediction : খ')\n",
    "    elif res == 13:\n",
    "        print('prediction : গ')\n",
    "    elif res == 14:\n",
    "        print('prediction : ঘ')\n",
    "    elif res == 15:\n",
    "        print('prediction : ঙ')\n",
    "    elif res == 16:\n",
    "        print('prediction : চ')\n",
    "    elif res == 17:\n",
    "        print('prediction : ছ')\n",
    "    elif res == 18:\n",
    "        print('prediction : জ')\n",
    "    elif res == 19:\n",
    "        print('prediction : ঝ')\n",
    "    elif res == 20:\n",
    "        print('prediction : ঞ')\n",
    "    elif res == 21:\n",
    "        print('prediction : ট')\n",
    "    elif res == 22:\n",
    "        print('prediction : ঠ')\n",
    "    elif res == 23:\n",
    "        print('prediction : ড')\n",
    "    elif res == 24:\n",
    "        print('prediction : ঢ')\n",
    "    elif res == 25:\n",
    "        print('prediction : ণ')\n",
    "    elif res == 26:\n",
    "        print('prediction : ত')\n",
    "    elif res == 27:\n",
    "        print('prediction : থ')\n",
    "    elif res == 28:\n",
    "        print('prediction : দ')\n",
    "    elif res == 29:\n",
    "        print('prediction : ধ')\n",
    "    elif res == 30:\n",
    "        print('prediction : ন')\n",
    "    elif res == 31:\n",
    "        print('prediction : প')\n",
    "    elif res == 32:\n",
    "        print('prediction : ফ')\n",
    "    elif res == 33:\n",
    "        print('prediction : ব')\n",
    "    elif res == 34:\n",
    "        print('prediction : ভ')\n",
    "    elif res == 35:\n",
    "        print('prediction : ম')\n",
    "    elif res == 36:\n",
    "        print('prediction : য')\n",
    "    elif res == 37:\n",
    "        print('prediction : র')\n",
    "    elif res == 38:\n",
    "        print('prediction : ল')\n",
    "    elif res == 39:\n",
    "        print('prediction : শ')\n",
    "    elif res == 40:\n",
    "        print('prediction : ষ')\n",
    "    elif res == 41:\n",
    "        print('prediction : স')\n",
    "    elif res == 42:\n",
    "        print('prediction : হ')\n",
    "    elif res == 43:\n",
    "        print('prediction : ড়')\n",
    "    elif res == 44:\n",
    "        print('prediction : ঢ়')\n",
    "    elif res == 45:\n",
    "        print('prediction : য়')\n",
    "    elif res == 46:\n",
    "        print('prediction : ৎ')\n",
    "    elif res == 47:\n",
    "        print('prediction : ং')\n",
    "    elif res == 48:\n",
    "        print('prediction : ঃ')\n",
    "    else:\n",
    "        print('prediction : ঁ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def single_prediction(test_img):\n",
    "    test_img_arr = image.img_to_array(test_img)\n",
    "    test_img_arr = np.expand_dims(test_img_arr, axis = 0)\n",
    "    prediction = classifier.predict(test_img_arr)\n",
    "    result = np.argmax(prediction, axis = 1)\n",
    "    determine_character(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_created_image():\n",
    "    os.remove('F:\\Bengali-Handwritten-Character-Recognition-main\\Dataset\\Predict\\image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_n_guess_the_character():\n",
    "    create_new_image()\n",
    "    test_img = image.load_img('F:\\Bengali-Handwritten-Character-Recognition-main\\Dataset\\Predict\\image.jpg', target_size = (40, 40, 3))\n",
    "    single_prediction(test_img)\n",
    "    plt.imshow(test_img)\n",
    "    delete_created_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : ক\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPp0lEQVR4nO3dXYhc533H8d/Pa0nWi6W1vJIQllwFY0qCaVQQIpBeuHFcVFOQXXCIL4IKBvsihgRyEZGbOIWCL+y4Fy2GmAirJU0qSFKL4r4IkZAGgmPFKI5cObUxqiNb1motryzr/eXfiz0KquY50pk558yemef7ATEzz56Z85wd/fbsPvOc5++IEIDxd9N8dwDAcBB2IBOEHcgEYQcyQdiBTBB2IBO1wm57i+3f2n7L9vamOgWgeR70c3bbE5L+R9L9kg5LekXSIxHx32XPmZqaig0bNgy0PwA3dujQIc3MzDj1tZtrvO5mSW9FxNuSZPsHkrZKKg37hg0btG/fvhq7BHA9mzZtKv1anV/j75D0u6seHy7aAHRQnbCnflXo+ZvA9mO299ned+zYsRq7A1BHnbAflrT+qsfrJL137UYR8Z2I2BQRm1atWlVjdwDqqBP2VyTdbfsTthdK+qKk3c10C0DTBh6gi4iLtp+Q9B+SJiTtiIjXG+sZgEbVGY1XRLwk6aWG+gKgRcygAzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFM1FqWyvYhSSclXZJ0MSLKV6gHMK9qhb3wpxEx08DrAGgRv8YDmagb9pD0n7Z/ZfuxJjoEoB11f43/bES8Z3u1pD2234iIn129QfFD4DFJuvPOO2vuDsCgap3ZI+K94nZa0o81V9n12m0o/wR0wMBht73U9q1X7kv6M0kHmuoYgGbV+TV+jaQf277yOv8UEf/eSK8ANK5Orbe3JX26wb4AaBEfvQGZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZaGLxik4qpvFWal+yZEly21OnTlV6/sKFC5PPP3fuXE9bRCS3HQfnz5/vaVu0aFFy21R76vtVZunSpcn2m27qPX+l+lVmnN8zzuxAJgg7kAnCDmSCsAOZ6OwA3cWLF3vaygZaJicnK79uarAlNRDXz/PLBpYmJiZ62pYvX57cNnW8ZYNby5Yt62k7efJkcttUfz/66KPktqnBrdTg46VLl5LPv3DhQrI9pZ/BuJR+3jPM4cwOZIKwA5kg7EAmCDuQiRsO0NneIekvJE1HxD1F20pJ/yxpg6RDkr4QER822bHUAE5qYKrLUgNZZQNpKWfOnEm2z87ODtql67p8+XJP29mzZ1vZV1elvgfjosqZ/QVJW65p2y5pb0TcLWlv8RhAh90w7EWFl+PXNG+VtLO4v1PSg812C0DTBv2bfU1EHJGk4nZ12Ya2H7O9z/a+Y8eODbg7AHW1PkBH+SegGwYN+1HbayWpuJ1urksA2jDodNndkrZJeqq4fbGxHhVS1yuXXaOeGkHt53r2MuNyHXNVCxYs6GlLTYFNbVem7BOU1CcNwxz5z+29lSqc2W1/X9IvJP2h7cO2H9VcyO+3/aak+4vHADrshmf2iHik5Ev3NdwXAC1iBh2QCcIOZKKz17On9DOVsa0BmNSAVdmCk1UHvPrVz6KXKWXXkqe+v6mpuf2sH/Dhh43Oor6h1Pcm9X+hbKA2dU1/2fX7o4YzO5AJwg5kgrADmSDsQCYIO5CJkRqN76qyEfabb+799pZ9opB6jbLVZW+//faetg8++CC5bWo127JVelOjzitXrkxu21V1P4VZsWJFT1vZyP2oTbnlzA5kgrADmSDsQCYIO5AJBuj61M+13Cmp6ZhSejCurG786dOnK++vn9VsU7qw2mo/013rGvb03mHizA5kgrADmSDsQCYIO5CJKmvQ7bA9bfvAVW1P2n7X9v7i3wPtdhNAXVVG41+Q9HeS/uGa9mcj4unGezRGUtNPJyYmktumptY2sdBFStk03NQ02rZG41OvW/bpQ+oTkGFOYU29N6No0PJPAEZMnb/Zn7D9WvFr/m2N9QhAKwYN+3OS7pK0UdIRSc+UbUitN6AbBgp7RByNiEsRcVnS85I2X2dbar0BHTDQyIPttVequEp6SNKB622fq9QAXdkqsMNcwbRsddmUmZmZnrapqanafUhNG26r/FNbU2vrlsYathuGvSj/dK+kKduHJX1T0r22N0oKSYckPd5eFwE0YdDyT99toS8AWsQMOiAThB3IBGEHMjEe8wA7aunSpT1to1Y3bNRWl02pu/jFxYsXk+1dHnlP4cwOZIKwA5kg7EAmCDuQCQbo+nTLLbf0tJVNPx1meaCyQaS6ylbDHSXHj9e7Qjv1no+i0X8nAVRC2IFMEHYgE4QdyARhBzLBaPx1pFY7TY28d6EeWlsroKZWnC1bgKMLUu/ZmTNnar1m2fNTNffKVsjtAs7sQCYIO5AJwg5kokr5p/W2f2L7oO3XbX+laF9pe4/tN4tb1o4HOqzKqM5FSV+LiFdt3yrpV7b3SPorSXsj4inb2yVtl/T19rransWLFyfbU4Nxw5wC2wVdGHxMKbsePfVe9nM9++TkZE9bapBS6vZgXEqV8k9HIuLV4v5JSQcl3SFpq6SdxWY7JT3YUh8BNKCvv9ltb5D0x5JelrTmytrxxe3qxnsHoDGVw257maQfSvpqRHzUx/Mo/wR0QKWw216guaB/LyJ+VDQftb22+PpaSdOp51L+CeiGKhVhrLmiEAcj4ttXfWm3pG2SnipuX2ylhw3rZ6HBVOmjEydO9LStWLGiVp+6bJjXcjexsGNqtls/73lqX12eMdiPKqPxn5X0JUm/sb2/aPuG5kK+y/ajkt6R9HArPQTQiCrln34uqexH433NdgdAW5hBB2SCsAOZIOxAJsb2evZ+RmDLTE1NVXrd6enkp47J57elbErnKCmbttyGsuv/y97LccCZHcgEYQcyQdiBTBB2IBNjMUCXmsJaNgBTt0xSaoCubM7/MK99b6vue+p1JyYmWtlXW+9ZSlnJrnHGmR3IBGEHMkHYgUwQdiAThB3IxFiMxqdWBG1LP6utpkbu2xqhb2uqaVsj7yllZZaWLl3a05YqvVQmtxWBy3BmBzJB2IFMEHYgE3XKPz1p+13b+4t/D7TfXQCDqlP+SZKejYin2+hYaprmkSNHktv2U94n5dZbb022nzx5svJrVFXWr64OIqWmqrZVC77M7OxsT9v777+f3Pa22yg5WKbKgpNHJF2p/HLS9pXyTwBGSJ3yT5L0hO3XbO+giivQbXXKPz0n6S5JGzV35n+m5HmUfwI6YODyTxFxNCIuRcRlSc9L2px6LuWfgG6oMhqfLP90pc5b4SFJB5rvHoCm1Cn/9IjtjZJC0iFJjzfZsdQ0zXXr1lV+fj+j22Uj5KlR5zYWUijrQz/HcOHChSa783upWm9tfQ/KpOqvrV+/fqh9GAd1yj+91Hx3ALSFGXRAJgg7kAnCDmRiLK5nr6tsICw1aJYasDp79mzjfSrbvySdOnWqp23JkiWt9OGmmzgfjAveSSAThB3IBGEHMkHYgUwQdiATjMZfR2oKamrq5rClVltta/GL48ePt/K6GD7O7EAmCDuQCcIOZIKwA5lggO46Utez113Jti1N9CFVQiq18m5XV8LF9XFmBzJB2IFMEHYgE1UWnLzF9i9t/7oo//Ston2l7T223yxuWTce6LAqA3TnJH0uIj4ulpT+ue1/k/SXkvZGxFO2t0vaLunrLfa1s8oGrFKLZvZT370fZXXUU+3nzp1Lbpsa5BtmfXa064Zn9pjzcfFwQfEvJG2VtLNo3ynpwTY6CKAZVYtETBTLSE9L2hMRL0taU9SBu1IPbnVrvQRQW6WwF5VfNkpaJ2mz7Xuq7oDyT0A39DUaHxGzkn4qaYuko1eqwhS30yXPofwT0AFVRuNX2Z4s7i+W9HlJb0jaLWlbsdk2SS+21EcADagyGr9W0k7bE5r74bArIv7V9i8k7bL9qKR3JD3cYj9HUmrV2cnJyeS2p0+frrWvS5cuVW7vZ2otq8uOjyrln17TXE32a9s/kHRfG50C0Dx+bAOZIOxAJgg7kAmuZ29RanHKVOkmqb9Bs2HWjT9//nwrr4vh48wOZIKwA5kg7EAmCDuQCcIOZILR+CErWziin1VrUyPvZQto9DPKv2LFikr7Sn0agO7jzA5kgrADmSDsQCYIO5AJRlqGbNGiRZW3Xb58ebJ9Zmampy1VS77MwoULk+2zs7OVXwOjhzM7kAnCDmSCsAOZqFP+6Unb79reX/x7oP3uAhhUnfJPkvRsRDzdXvcANKXKgpMhKVX+CS07ceJE7dcom0aL/NQp/yRJT9h+zfYOqrgC3Van/NNzku6StFHSEUnPpJ5L+SegGwYu/xQRR4sfApclPS9pc8lzKP8EdMDA5Z+u1HkrPCTpQCs9BNCIOuWf/tH2Rs0N1h2S9HhrvQRQW53yT19qpUcAWsEMOiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUx4mOWBbB+T9L/FwylJM0Pb+fBwXKNnnI7tDyIiWaBhqGH/fzu290XEpnnZeYs4rtEzzsd2NX6NBzJB2IFMzGfYvzOP+24TxzV6xvnYfm/e/mYHMFz8Gg9kYuhht73F9m9tv2V7+7D33yTbO2xP2z5wVdtK23tsv1nc3jaffRyE7fW2f2L7oO3XbX+laB/pY7N9i+1f2v51cVzfKtpH+riqGmrYi0qwfy/pzyV9StIjtj81zD407AVJW65p2y5pb0TcLWlv8XjUXJT0tYj4pKTPSPpy8T6N+rGdk/S5iPi0pI2Sttj+jEb/uCoZ9pl9s6S3IuLtiDgv6QeStg65D42JiJ9JOn5N81ZJO4v7OyU9OMw+NSEijkTEq8X9k5IOSrpDI35sMefj4uGC4l9oxI+rqmGH/Q5Jv7vq8eGibZysiYgj0lxoJK2e5/7UYnuD5kp2v6wxODbbE7b3S5qWtCcixuK4qhh22J1o4+OAjrK9TNIPJX01Ij6a7/40ISIuRcRGSeskbbZ9zzx3aWiGHfbDktZf9XidpPeG3Ie2HbW9VpKK2+l57s9AbC/QXNC/FxE/KprH4tgkKSJmJf1Uc2MuY3Nc1zPssL8i6W7bn7C9UNIXJe0ech/atlvStuL+NkkvzmNfBmLbkr4r6WBEfPuqL430sdleZXuyuL9Y0uclvaERP66qhj6pxvYDkv5W0oSkHRHxN0PtQINsf1/SvZq7auqopG9K+hdJuyTdKekdSQ9HxLWDeJ1m+08k/Zek30i6XDR/Q3N/t4/ssdn+I80NwE1o7kS3KyL+2vbtGuHjqooZdEAmmEEHZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQif8DoWsUa+CAvtoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_n_guess_the_character()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
