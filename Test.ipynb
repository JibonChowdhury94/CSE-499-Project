{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    }
   ],
   "source": [
    "print(2+220)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (40, 40, 3)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Dense(units = 50, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fitting the CNN model to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = .2, rotation_range = 25)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Dataset/Train', target_size = (40, 40),\n",
    "                                                 batch_size = 32, class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('Dataset/Test', target_size = (40, 40),\n",
    "                                            batch_size = 32, class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "358/358 [==============================] - ETA: 0s - loss: 3.4330 - accuracy: 0.1305WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "358/358 [==============================] - 160s 444ms/step - loss: 3.4311 - accuracy: 0.1310 - val_loss: 1.2074 - val_accuracy: 0.6607\n",
      "Epoch 2/15\n",
      "358/358 [==============================] - 144s 403ms/step - loss: 1.5437 - accuracy: 0.5660\n",
      "Epoch 3/15\n",
      "358/358 [==============================] - 128s 357ms/step - loss: 1.1982 - accuracy: 0.6493\n",
      "Epoch 4/15\n",
      "358/358 [==============================] - 123s 343ms/step - loss: 1.0288 - accuracy: 0.6876\n",
      "Epoch 5/15\n",
      "358/358 [==============================] - 120s 334ms/step - loss: 0.8818 - accuracy: 0.7362\n",
      "Epoch 6/15\n",
      "358/358 [==============================] - 123s 344ms/step - loss: 0.8283 - accuracy: 0.7472\n",
      "Epoch 7/15\n",
      "358/358 [==============================] - 130s 362ms/step - loss: 0.7415 - accuracy: 0.7715\n",
      "Epoch 8/15\n",
      "358/358 [==============================] - 125s 349ms/step - loss: 0.6885 - accuracy: 0.7929\n",
      "Epoch 9/15\n",
      "358/358 [==============================] - 121s 338ms/step - loss: 0.6616 - accuracy: 0.7962\n",
      "Epoch 10/15\n",
      "358/358 [==============================] - 119s 332ms/step - loss: 0.5921 - accuracy: 0.8170\n",
      "Epoch 11/15\n",
      "358/358 [==============================] - 121s 338ms/step - loss: 0.6096 - accuracy: 0.8061\n",
      "Epoch 12/15\n",
      "358/358 [==============================] - 119s 333ms/step - loss: 0.5604 - accuracy: 0.8271\n",
      "Epoch 13/15\n",
      "358/358 [==============================] - 120s 334ms/step - loss: 0.5357 - accuracy: 0.8377\n",
      "Epoch 14/15\n",
      "358/358 [==============================] - 121s 338ms/step - loss: 0.5212 - accuracy: 0.8362\n",
      "Epoch 15/15\n",
      "358/358 [==============================] - 119s 333ms/step - loss: 0.5259 - accuracy: 0.8360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1715a9a04f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_set, steps_per_epoch = 358, epochs = 15,\n",
    "                         validation_data = test_set, validation_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 38, 38, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 17, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "=================================================================\n",
      "Total params: 608,242\n",
      "Trainable params: 608,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "classifier_json = classifier.to_json()\n",
    "with open(\"ModelSaving.json\", \"w\") as json_file:\n",
    "        json_file.write(classifier_json)\n",
    "          \n",
    "classifier.save_weights(\"ModelSaving.h5\")\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graphical user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import ImageTk, ImageDraw, Image\n",
    "from tkinter import *\n",
    "from keras.preprocessing import image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_image():\n",
    "    width = 256\n",
    "    height = 256\n",
    "    center = height // 2\n",
    "    white = (255, 255, 255)\n",
    "    green = (0, 128, 0)\n",
    "    \n",
    "    def save():\n",
    "        filename = 'F:\\Bengali-Handwritten-Character-Recognition-main\\Dataset\\Predict\\image.jpg'\n",
    "        image.save(filename)\n",
    "        \n",
    "    def paint(event):\n",
    "        x1, y1 = (event.x - 1), (event.y - 1)\n",
    "        x2, y2 = (event.x + 1), (event.y + 1)\n",
    "        cv.create_oval(x1, y1, x2, y2, fill = 'black', width = 30)\n",
    "        draw.line([x1, y1, x2, y2], fill = 'black', width = 30)\n",
    "        \n",
    "    root = Tk()\n",
    "    \n",
    "    cv = Canvas(root, width = width, height = height, bg = 'white')\n",
    "    cv.pack()\n",
    "    \n",
    "    image = PIL.Image.new('RGB', (width, height), white)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    cv.pack(expand = YES, fill = BOTH)\n",
    "    cv.bind(\"<B1-Motion>\", paint)\n",
    "    \n",
    "    button = Button(text = 'Save', command = save)\n",
    "    button.pack()\n",
    "    \n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_character(res):\n",
    "    if res == 0:\n",
    "        print('prediction : অ')\n",
    "    elif res == 1:\n",
    "        print('prediction : আ')\n",
    "    elif res == 2:\n",
    "        print('prediction : ই')\n",
    "    elif res == 3:\n",
    "        print('prediction : ঈ')\n",
    "    elif res == 4:\n",
    "        print('prediction : উ')\n",
    "    elif res == 5:\n",
    "        print('prediction : ঊ')\n",
    "    elif res == 6:\n",
    "        print('prediction : ঋ')\n",
    "    elif res == 7:\n",
    "        print('prediction : এ')\n",
    "    elif res == 8:\n",
    "        print('prediction : ঐ')\n",
    "    elif res == 9:\n",
    "        print('prediction : ও')\n",
    "    elif res == 10:\n",
    "        print('prediction : ঔ')\n",
    "    elif res == 11:\n",
    "        print('prediction : ক')\n",
    "    elif res == 12:\n",
    "        print('prediction : খ')\n",
    "    elif res == 13:\n",
    "        print('prediction : গ')\n",
    "    elif res == 14:\n",
    "        print('prediction : ঘ')\n",
    "    elif res == 15:\n",
    "        print('prediction : ঙ')\n",
    "    elif res == 16:\n",
    "        print('prediction : চ')\n",
    "    elif res == 17:\n",
    "        print('prediction : ছ')\n",
    "    elif res == 18:\n",
    "        print('prediction : জ')\n",
    "    elif res == 19:\n",
    "        print('prediction : ঝ')\n",
    "    elif res == 20:\n",
    "        print('prediction : ঞ')\n",
    "    elif res == 21:\n",
    "        print('prediction : ট')\n",
    "    elif res == 22:\n",
    "        print('prediction : ঠ')\n",
    "    elif res == 23:\n",
    "        print('prediction : ড')\n",
    "    elif res == 24:\n",
    "        print('prediction : ঢ')\n",
    "    elif res == 25:\n",
    "        print('prediction : ণ')\n",
    "    elif res == 26:\n",
    "        print('prediction : ত')\n",
    "    elif res == 27:\n",
    "        print('prediction : থ')\n",
    "    elif res == 28:\n",
    "        print('prediction : দ')\n",
    "    elif res == 29:\n",
    "        print('prediction : ধ')\n",
    "    elif res == 30:\n",
    "        print('prediction : ন')\n",
    "    elif res == 31:\n",
    "        print('prediction : প')\n",
    "    elif res == 32:\n",
    "        print('prediction : ফ')\n",
    "    elif res == 33:\n",
    "        print('prediction : ব')\n",
    "    elif res == 34:\n",
    "        print('prediction : ভ')\n",
    "    elif res == 35:\n",
    "        print('prediction : ম')\n",
    "    elif res == 36:\n",
    "        print('prediction : য')\n",
    "    elif res == 37:\n",
    "        print('prediction : র')\n",
    "    elif res == 38:\n",
    "        print('prediction : ল')\n",
    "    elif res == 39:\n",
    "        print('prediction : শ')\n",
    "    elif res == 40:\n",
    "        print('prediction : ষ')\n",
    "    elif res == 41:\n",
    "        print('prediction : স')\n",
    "    elif res == 42:\n",
    "        print('prediction : হ')\n",
    "    elif res == 43:\n",
    "        print('prediction : ড়')\n",
    "    elif res == 44:\n",
    "        print('prediction : ঢ়')\n",
    "    elif res == 45:\n",
    "        print('prediction : য়')\n",
    "    elif res == 46:\n",
    "        print('prediction : ৎ')\n",
    "    elif res == 47:\n",
    "        print('prediction : ং')\n",
    "    elif res == 48:\n",
    "        print('prediction : ঃ')\n",
    "    else:\n",
    "        print('prediction : ঁ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def single_prediction(test_img):\n",
    "    test_img_arr = image.img_to_array(test_img)\n",
    "    test_img_arr = np.expand_dims(test_img_arr, axis = 0)\n",
    "    prediction = classifier.predict(test_img_arr)\n",
    "    result = np.argmax(prediction, axis = 1)\n",
    "    determine_character(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_created_image():\n",
    "    os.remove('F:\\Bengali-Handwritten-Character-Recognition-main\\Dataset\\Predict\\image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_n_guess_the_character():\n",
    "    create_new_image()\n",
    "    test_img = image.load_img('F:\\Bengali-Handwritten-Character-Recognition-main\\Dataset\\Predict\\image.jpg', target_size = (40, 40, 3))\n",
    "    single_prediction(test_img)\n",
    "    plt.imshow(test_img)\n",
    "    delete_created_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : অ\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_n_guess_the_character()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
